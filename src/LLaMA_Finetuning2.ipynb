{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "A100",
      "machine_shape": "hm"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "6c5b9a0ba9874a988213bf30a499bfe0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_f84f84e3ef494798a7fcf6c428bc30c7",
              "IPY_MODEL_cdcbc905d1fe4b9f9f25077d680d0e1d",
              "IPY_MODEL_d0f8440f1ae8499c9c20f4a7c1af178e"
            ],
            "layout": "IPY_MODEL_742b0d026d9c4a0e9458ca3c7f23c58a"
          }
        },
        "f84f84e3ef494798a7fcf6c428bc30c7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_a4b9c63a4f91485cb82451ea9951b26f",
            "placeholder": "​",
            "style": "IPY_MODEL_618198f7431f4d36ac6030661fd6a699",
            "value": "Loading checkpoint shards: 100%"
          }
        },
        "cdcbc905d1fe4b9f9f25077d680d0e1d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_9e8d8a48ee0146c0a5ee494aaae2f777",
            "max": 33,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_ca916e2746394c57ab7da73f7326743a",
            "value": 33
          }
        },
        "d0f8440f1ae8499c9c20f4a7c1af178e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_3d609be6205f411a98e3ad9bec5c4f3e",
            "placeholder": "​",
            "style": "IPY_MODEL_8db732c9b50a488590791efed7f73b86",
            "value": " 33/33 [00:18&lt;00:00,  1.70it/s]"
          }
        },
        "742b0d026d9c4a0e9458ca3c7f23c58a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a4b9c63a4f91485cb82451ea9951b26f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "618198f7431f4d36ac6030661fd6a699": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "9e8d8a48ee0146c0a5ee494aaae2f777": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ca916e2746394c57ab7da73f7326743a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "3d609be6205f411a98e3ad9bec5c4f3e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "8db732c9b50a488590791efed7f73b86": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "09266eaf36a844e1b062f0a9496b7c71": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_f97e6da9f7414db585f6a50510da8447",
              "IPY_MODEL_adafe79e116044ad8f329b747364bca4",
              "IPY_MODEL_ba712783c5a74abd86ced2a929c1aedd"
            ],
            "layout": "IPY_MODEL_afb98c3157474fed8142fdc67839efaf"
          }
        },
        "f97e6da9f7414db585f6a50510da8447": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_d2229090f74647d686318cda742b1880",
            "placeholder": "​",
            "style": "IPY_MODEL_873dc4bf009b42febe066c746da02f26",
            "value": "Loading checkpoint shards: 100%"
          }
        },
        "adafe79e116044ad8f329b747364bca4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_c892275352d84ef8906e603dc021bdb9",
            "max": 6,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_3872fe668b714b4e9fb636bc1415f427",
            "value": 6
          }
        },
        "ba712783c5a74abd86ced2a929c1aedd": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_e08f71b5db014e6bbd5c09f04f367e15",
            "placeholder": "​",
            "style": "IPY_MODEL_e0461a11bf0c40be8ea53616acb7f11a",
            "value": " 6/6 [01:13&lt;00:00, 11.19s/it]"
          }
        },
        "afb98c3157474fed8142fdc67839efaf": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d2229090f74647d686318cda742b1880": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "873dc4bf009b42febe066c746da02f26": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "c892275352d84ef8906e603dc021bdb9": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "3872fe668b714b4e9fb636bc1415f427": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "e08f71b5db014e6bbd5c09f04f367e15": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e0461a11bf0c40be8ea53616acb7f11a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# AKI Seminar2 Demo\n",
        "## Finetuning of LLaMA\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "by Syon Kadkade\n",
        "\n",
        "\n",
        "Table of contents\n",
        "\n",
        "> [Install packages](#install)   \n",
        "> [Import libaries](#imports)   \n",
        "> [Lorem Ipsum]()\n",
        "\n",
        "\n",
        "**Resources**:\n",
        "- [Meta AI Paper: LLaMA: Open and Efficient Foundation Language Models](#https://arxiv.org/abs/2302.13971)"
      ],
      "metadata": {
        "id": "8fB3xqHnZJ_j"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!nvidia-smi"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZnsQ0VgIwMdM",
        "outputId": "03bcb992-43a4-4820-a49a-d389fb056ca5"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fri Jan 19 10:20:37 2024       \n",
            "+---------------------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 535.104.05             Driver Version: 535.104.05   CUDA Version: 12.2     |\n",
            "|-----------------------------------------+----------------------+----------------------+\n",
            "| GPU  Name                 Persistence-M | Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp   Perf          Pwr:Usage/Cap |         Memory-Usage | GPU-Util  Compute M. |\n",
            "|                                         |                      |               MIG M. |\n",
            "|=========================================+======================+======================|\n",
            "|   0  Tesla V100-SXM2-16GB           Off | 00000000:00:04.0 Off |                    0 |\n",
            "| N/A   37C    P0              26W / 300W |      0MiB / 16384MiB |      0%      Default |\n",
            "|                                         |                      |                  N/A |\n",
            "+-----------------------------------------+----------------------+----------------------+\n",
            "                                                                                         \n",
            "+---------------------------------------------------------------------------------------+\n",
            "| Processes:                                                                            |\n",
            "|  GPU   GI   CI        PID   Type   Process name                            GPU Memory |\n",
            "|        ID   ID                                                             Usage      |\n",
            "|=======================================================================================|\n",
            "|  No running processes found                                                           |\n",
            "+---------------------------------------------------------------------------------------+\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "--------------\n",
        "<a id=\"install\"></a>\n",
        "### Install packages[Emoji]\n",
        "\n",
        "**Description**:   \n",
        "lorem ipsum"
      ],
      "metadata": {
        "id": "II2Y9dR4j1Ah"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install accelerate --quiet\n",
        "!pip install bitsandbytes --quiet\n",
        "!pip install datasets --quiet\n",
        "!pip install -q gradio --quiet\n",
        "!pip install -q git+https://github.com/huggingface/peft.git"
      ],
      "metadata": {
        "id": "7AJAViuMkKCE",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5fa44508-a69e-4b85-f954-a23041a366d1"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install sentencepiece\n",
        "!pip install accelerate --quiet"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "h3PFJWC1m_Eu",
        "outputId": "bf3f27a9-a116-4ac3-f2d9-9da51cccda71"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting sentencepiece\n",
            "  Downloading sentencepiece-0.1.99-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.3 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.3/1.3 MB\u001b[0m \u001b[31m9.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: sentencepiece\n",
            "Successfully installed sentencepiece-0.1.99\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m270.9/270.9 kB\u001b[0m \u001b[31m4.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "---------------\n",
        "<a id=\"imports\"></a>\n",
        "### Import libaries [Emoji]\n",
        "**Description**:   \n",
        "Load all necessary libaries."
      ],
      "metadata": {
        "id": "j7KhuNwXhAoc"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "RzYMEFm-ZFdG"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import torch\n",
        "import transformers\n",
        "import gradio as gr\n",
        "from datasets import load_dataset\n",
        "from peft import LoraConfig, TaskType\n",
        "from peft import get_peft_model\n",
        "from accelerate import Accelerator\n",
        "from transformers import AutoTokenizer, AutoModelForCausalLM, DataCollatorWithPadding, DataCollatorForSeq2Seq, GenerationConfig, TrainingArguments, Trainer"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import warnings\n",
        "warnings.filterwarnings('ignore')"
      ],
      "metadata": {
        "id": "CI0JPCnVdx3v"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "DEVICE = \"cuda:0\" if torch.cuda.is_available() else \"cpu\"\n",
        "DEVICE"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "pbYRKdV8y2WB",
        "outputId": "155b631c-7d6e-40d5-d4de-01853ce8ee78"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'cuda:0'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "-----------------\n",
        "### Load LLaMA-7B-Model[Emoji]\n",
        "\n",
        "**Description**:  \n",
        "lorem ipsum dolor sit amet\n",
        "\n",
        "**Resources**:\n",
        "- [Tutorial](#https://www.youtube.com/watch?v=t68IV5t5UOA)\n",
        "- [Hugging Face: Transformer Tutorial](#https://huggingface.co/learn/nlp-course/chapter2/2?fw=pt)\n",
        "- [Hugging Face: LLaMA-7B-Model](https://huggingface.co/docs/transformers/main/model_doc/llama)\n",
        "- [Hugging Face: LLaMA weights](https://huggingface.co/luodian/llama-7b-hf)\n",
        "- [Hugging Face: 7B Weights](#https://huggingface.co/huggyllama/llama-7b)\n",
        "\n",
        "**Note**: I use a model that has the weights in it and we introduce these into the actual LLaMA model. Normally you have to request the weights from Meta AI by filling out a form. I have filled it out several times but there is no response from them."
      ],
      "metadata": {
        "id": "jHc82F3lhNvX"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "----------------\n",
        "### Load Alpaca dataset\n",
        "**Rescources**:\n",
        "- [HuggingFace: datasets tutorial](#https://huggingface.co/docs/datasets/tutorial)\n",
        "- [HuggingFace: vicgale/alpaca-gpt4 dataset](#https://huggingface.co/datasets/vicgalle/alpaca-gpt4)"
      ],
      "metadata": {
        "id": "40D8Fnu56OQ1"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "----------------\n",
        "### Prepare Trainer for finetuning\n",
        "Do it via Trainer API or with own training pipeline"
      ],
      "metadata": {
        "id": "bPAmbHIMrZcV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#MODEL_NAME= \"TheBloke/Llama-2-7B-GPTQ\"\n",
        "#MODEL_NAME = 'huggyllama/llama-7b'\n",
        "MODEL_NAME = \"Enoch/llama-7b-hf\"\n",
        "#MODEL_NAME = \"baffo32/decapoda-research-llama-7B-hf\"\n",
        "#PEFT_MODEL_NAME = \"tloen/alpaca-lora-7b\"\n",
        "#PEFT_MODEL_NAME = \"dominguesm/alpaca-lora-ptbr-7b\"\n",
        "#PEFT_MODEL_NAME = \"Eterna2/alpaca-lora-7b\""
      ],
      "metadata": {
        "id": "xpP5bXj3U6J_"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tokenizer = AutoTokenizer.from_pretrained(MODEL_NAME)\n",
        "tokenizer.pad_token_id = (0)\n",
        "tokenizer.padding_side = \"left\""
      ],
      "metadata": {
        "id": "0mZGQj2JMtCo",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "716f0457-dba3-401d-c00c-62da7519d69c"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "You are using the default legacy behaviour of the <class 'transformers.models.llama.tokenization_llama.LlamaTokenizer'>. This is expected, and simply means that the `legacy` (previous) behavior will be used so nothing changes for you. If you want to use the new behaviour, set `legacy=False`. This should only be set if you understand what it means, and thouroughly read the reason why this was added as explained in https://github.com/huggingface/transformers/pull/24565\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "dataset = load_dataset(\"imdb\")\n",
        "dataset"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "P4VDGlsTFgEK",
        "outputId": "9972be73-3030-40a2-b6eb-9662244197f3"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "DatasetDict({\n",
              "    train: Dataset({\n",
              "        features: ['text', 'label'],\n",
              "        num_rows: 25000\n",
              "    })\n",
              "    test: Dataset({\n",
              "        features: ['text', 'label'],\n",
              "        num_rows: 25000\n",
              "    })\n",
              "    unsupervised: Dataset({\n",
              "        features: ['text', 'label'],\n",
              "        num_rows: 50000\n",
              "    })\n",
              "})"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def preprocess_function(examples):\n",
        "    return tokenizer(examples[\"text\"], truncation=True)"
      ],
      "metadata": {
        "id": "Ocn_Agc0FQuV"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tokenized_imdb = dataset.map(preprocess_function, batched=True)"
      ],
      "metadata": {
        "id": "pw5UWUPEFV36"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tokenized_imdb_train = tokenized_imdb[\"train\"].select(range(10))\n",
        "tokenized_imdb_train"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "M-xpu5rId7Rx",
        "outputId": "97b0cfa1-fa96-4202-e44b-14ff67631172"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Dataset({\n",
              "    features: ['text', 'label', 'input_ids', 'attention_mask'],\n",
              "    num_rows: 10\n",
              "})"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "tokenized_imdb_test = tokenized_imdb[\"test\"].select(range(10))\n",
        "tokenized_imdb_test"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xMEUHrZOekNg",
        "outputId": "7ac0e4ed-e492-492e-837e-27d4cc9b50a5"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Dataset({\n",
              "    features: ['text', 'label', 'input_ids', 'attention_mask'],\n",
              "    num_rows: 10\n",
              "})"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "data_collator = DataCollatorWithPadding(tokenizer=tokenizer)"
      ],
      "metadata": {
        "id": "NGLbBXGRFscE"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "id2label = {0: \"NEGATIVE\", 1: \"POSITIVE\"}\n",
        "label2id = {\"NEGATIVE\": 0, \"POSITIVE\": 1}"
      ],
      "metadata": {
        "id": "6jFY86rnGBPT"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import AutoModelForSequenceClassification\n",
        "model = AutoModelForSequenceClassification.from_pretrained(MODEL_NAME, num_labels=2, id2label=id2label, label2id=label2id)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 84,
          "referenced_widgets": [
            "6c5b9a0ba9874a988213bf30a499bfe0",
            "f84f84e3ef494798a7fcf6c428bc30c7",
            "cdcbc905d1fe4b9f9f25077d680d0e1d",
            "d0f8440f1ae8499c9c20f4a7c1af178e",
            "742b0d026d9c4a0e9458ca3c7f23c58a",
            "a4b9c63a4f91485cb82451ea9951b26f",
            "618198f7431f4d36ac6030661fd6a699",
            "9e8d8a48ee0146c0a5ee494aaae2f777",
            "ca916e2746394c57ab7da73f7326743a",
            "3d609be6205f411a98e3ad9bec5c4f3e",
            "8db732c9b50a488590791efed7f73b86"
          ]
        },
        "id": "Heez1_trGd5L",
        "outputId": "9182e798-1936-42cb-aa98-feda1dc1a031"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Loading checkpoint shards:   0%|          | 0/33 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "6c5b9a0ba9874a988213bf30a499bfe0"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of LlamaForSequenceClassification were not initialized from the model checkpoint at Enoch/llama-7b-hf and are newly initialized: ['score.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "lora_config = LoraConfig(\n",
        "    r=8,\n",
        "    lora_alpha=16,\n",
        "    target_modules=[\"q_proj\", \"v_proj\"],\n",
        "    lora_dropout=0.05,\n",
        "    bias=\"none\",\n",
        "    task_type=TaskType.CAUSAL_LM\n",
        "\n",
        ")"
      ],
      "metadata": {
        "id": "8pRY5Xa4MLyP"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "lora_model = get_peft_model(model=model, peft_config=lora_config)\n",
        "lora_model.print_trainable_parameters()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8uWcuJZLMSWt",
        "outputId": "e7b4e770-9813-48d0-bedd-f1ecb0e0d14b"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "trainable params: 4,194,304 || all params: 6,611,546,112 || trainable%: 0.06343907958816639\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "lora_model.config.use_cache = False\n",
        "#lora_model.config.quantization_config.to_dict()"
      ],
      "metadata": {
        "id": "fOzI-OqFJ4yv"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#gradient_accumulation_steps = Bacth_size // Micro_Batch_Size\n",
        "\"\"\"\n",
        "training_args = TrainingArguments(\n",
        "    per_device_train_batch_size=4,\n",
        "    gradient_accumulation_steps= (128 // 4),\n",
        "    warmup_steps=100,\n",
        "    max_steps=300,\n",
        "    learning_rate=3e-4,\n",
        "    logging_steps=10,\n",
        "    optim=\"adamw_torch\",\n",
        "    evaluation_strategy=\"epoch\",\n",
        "    save_strategy=\"epoch\",\n",
        "    eval_steps=50,\n",
        "    save_steps=50,\n",
        "    output_dir=\"./content/experiments\",\n",
        "    save_total_limit=3,\n",
        "    load_best_model_at_end=True\n",
        ")\n",
        "\"\"\""
      ],
      "metadata": {
        "id": "ZfqVQFXurZis",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 70
        },
        "outputId": "866ccef1-ab39-4bb0-9f4f-36821826eb8c"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'\\ntraining_args = TrainingArguments(\\n    per_device_train_batch_size=4,\\n    gradient_accumulation_steps= (128 // 4),\\n    warmup_steps=100,\\n    max_steps=300,\\n    learning_rate=3e-4,\\n    logging_steps=10,\\n    optim=\"adamw_torch\",\\n    evaluation_strategy=\"epoch\",\\n    save_strategy=\"epoch\",\\n    eval_steps=50,\\n    save_steps=50,\\n    output_dir=\"./content/experiments\",\\n    save_total_limit=3,\\n    load_best_model_at_end=True\\n)\\n'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "training_args = TrainingArguments(\n",
        "    learning_rate=3e-4,\n",
        "    gradient_accumulation_steps=20,\n",
        "    per_device_train_batch_size=1,\n",
        "    per_device_eval_batch_size=1,\n",
        "    num_train_epochs=1,\n",
        "    fp16=False,\n",
        "    evaluation_strategy=\"steps\",\n",
        "    save_strategy=\"steps\",\n",
        "    optim=\"adafactor\",\n",
        "    output_dir=\"./content/experiments\",\n",
        "    load_best_model_at_end=True\n",
        ")"
      ],
      "metadata": {
        "id": "Hoi_ltc5IDUw"
      },
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "trainer = Trainer(\n",
        "    model=model,\n",
        "    args=training_args,\n",
        "    train_dataset=tokenized_imdb_train,\n",
        "    eval_dataset=tokenized_imdb_test,\n",
        "    data_collator=data_collator\n",
        ")"
      ],
      "metadata": {
        "id": "AbHZHA_ZsA7l"
      },
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "torch.cuda.empty_cache()"
      ],
      "metadata": {
        "id": "FbnnwAyvvVYs"
      },
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "----------------\n",
        "### Finetune Model"
      ],
      "metadata": {
        "id": "JO1YB6Bcsb_k"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "trainer.train()"
      ],
      "metadata": {
        "id": "3DsbF5U5sbJb",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 147
        },
        "outputId": "f3e4711e-e5d1-4aca-e992-4e871e51ea7d"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "You're using a LlamaTokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='1' max='1' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [1/1 00:00, Epoch 1/1]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Step</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "  </tbody>\n",
              "</table><p>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "TrainOutput(global_step=1, training_loss=0.1618174910545349, metrics={'train_runtime': 7.1749, 'train_samples_per_second': 1.394, 'train_steps_per_second': 0.139, 'total_flos': 132551617486848.0, 'train_loss': 0.1618174910545349, 'epoch': 1.0})"
            ]
          },
          "metadata": {},
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.save_pretrained(\"/Content/llama_7b\", from_pt=True)"
      ],
      "metadata": {
        "id": "2PYs6DHPvie2"
      },
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "trained_model = AutoModelForSequenceClassification.from_pretrained(\"/Content/llama_7b\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 156,
          "referenced_widgets": [
            "09266eaf36a844e1b062f0a9496b7c71",
            "f97e6da9f7414db585f6a50510da8447",
            "adafe79e116044ad8f329b747364bca4",
            "ba712783c5a74abd86ced2a929c1aedd",
            "afb98c3157474fed8142fdc67839efaf",
            "d2229090f74647d686318cda742b1880",
            "873dc4bf009b42febe066c746da02f26",
            "c892275352d84ef8906e603dc021bdb9",
            "3872fe668b714b4e9fb636bc1415f427",
            "e08f71b5db014e6bbd5c09f04f367e15",
            "e0461a11bf0c40be8ea53616acb7f11a"
          ]
        },
        "id": "wNDT36TbwHwu",
        "outputId": "b228624f-4f7d-42ee-b25b-6053c40a9d8a"
      },
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Loading checkpoint shards:   0%|          | 0/6 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "09266eaf36a844e1b062f0a9496b7c71"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of the model checkpoint at /Content/llama_7b were not used when initializing LlamaForSequenceClassification: ['model.layers.5.self_attn.v_proj.lora_B.default.weight', 'model.layers.28.self_attn.v_proj.base_layer.weight', 'model.layers.22.self_attn.q_proj.lora_B.default.weight', 'model.layers.16.self_attn.q_proj.lora_B.default.weight', 'model.layers.3.self_attn.q_proj.lora_B.default.weight', 'model.layers.0.self_attn.v_proj.lora_A.default.weight', 'model.layers.26.self_attn.q_proj.base_layer.weight', 'model.layers.9.self_attn.v_proj.lora_B.default.weight', 'model.layers.14.self_attn.v_proj.lora_A.default.weight', 'model.layers.28.self_attn.q_proj.lora_B.default.weight', 'model.layers.21.self_attn.v_proj.lora_B.default.weight', 'model.layers.4.self_attn.q_proj.lora_B.default.weight', 'model.layers.13.self_attn.v_proj.base_layer.weight', 'model.layers.22.self_attn.q_proj.base_layer.weight', 'model.layers.3.self_attn.v_proj.lora_A.default.weight', 'model.layers.2.self_attn.v_proj.lora_A.default.weight', 'model.layers.3.self_attn.q_proj.base_layer.weight', 'model.layers.31.self_attn.q_proj.lora_B.default.weight', 'model.layers.4.self_attn.q_proj.lora_A.default.weight', 'model.layers.11.self_attn.v_proj.lora_A.default.weight', 'model.layers.17.self_attn.v_proj.lora_A.default.weight', 'model.layers.18.self_attn.q_proj.lora_A.default.weight', 'model.layers.10.self_attn.q_proj.lora_B.default.weight', 'model.layers.17.self_attn.v_proj.lora_B.default.weight', 'model.layers.26.self_attn.q_proj.lora_B.default.weight', 'model.layers.5.self_attn.v_proj.lora_A.default.weight', 'model.layers.3.self_attn.q_proj.lora_A.default.weight', 'model.layers.14.self_attn.v_proj.base_layer.weight', 'model.layers.18.self_attn.v_proj.lora_B.default.weight', 'model.layers.16.self_attn.v_proj.base_layer.weight', 'model.layers.13.self_attn.q_proj.base_layer.weight', 'model.layers.29.self_attn.v_proj.base_layer.weight', 'model.layers.1.self_attn.q_proj.lora_A.default.weight', 'model.layers.28.self_attn.v_proj.lora_A.default.weight', 'model.layers.4.self_attn.v_proj.lora_A.default.weight', 'model.layers.19.self_attn.q_proj.lora_B.default.weight', 'model.layers.0.self_attn.v_proj.lora_B.default.weight', 'model.layers.12.self_attn.q_proj.base_layer.weight', 'model.layers.24.self_attn.q_proj.base_layer.weight', 'model.layers.17.self_attn.q_proj.base_layer.weight', 'model.layers.23.self_attn.q_proj.lora_B.default.weight', 'model.layers.28.self_attn.v_proj.lora_B.default.weight', 'model.layers.16.self_attn.q_proj.lora_A.default.weight', 'model.layers.14.self_attn.q_proj.lora_A.default.weight', 'model.layers.22.self_attn.v_proj.lora_A.default.weight', 'model.layers.15.self_attn.v_proj.base_layer.weight', 'model.layers.28.self_attn.q_proj.lora_A.default.weight', 'model.layers.17.self_attn.q_proj.lora_B.default.weight', 'model.layers.16.self_attn.q_proj.base_layer.weight', 'model.layers.12.self_attn.v_proj.lora_A.default.weight', 'model.layers.7.self_attn.q_proj.lora_A.default.weight', 'model.layers.23.self_attn.q_proj.base_layer.weight', 'model.layers.30.self_attn.v_proj.lora_A.default.weight', 'model.layers.9.self_attn.q_proj.base_layer.weight', 'model.layers.29.self_attn.q_proj.lora_B.default.weight', 'model.layers.24.self_attn.v_proj.lora_A.default.weight', 'model.layers.10.self_attn.q_proj.lora_A.default.weight', 'model.layers.28.self_attn.q_proj.base_layer.weight', 'model.layers.13.self_attn.v_proj.lora_A.default.weight', 'model.layers.7.self_attn.q_proj.base_layer.weight', 'model.layers.30.self_attn.v_proj.lora_B.default.weight', 'model.layers.12.self_attn.v_proj.lora_B.default.weight', 'model.layers.31.self_attn.v_proj.lora_A.default.weight', 'model.layers.7.self_attn.v_proj.lora_A.default.weight', 'model.layers.8.self_attn.q_proj.lora_B.default.weight', 'model.layers.23.self_attn.v_proj.lora_B.default.weight', 'model.layers.27.self_attn.v_proj.lora_A.default.weight', 'model.layers.11.self_attn.q_proj.base_layer.weight', 'model.layers.20.self_attn.v_proj.lora_A.default.weight', 'model.layers.29.self_attn.v_proj.lora_A.default.weight', 'model.layers.20.self_attn.q_proj.lora_B.default.weight', 'model.layers.12.self_attn.q_proj.lora_A.default.weight', 'model.layers.21.self_attn.v_proj.base_layer.weight', 'model.layers.19.self_attn.v_proj.lora_A.default.weight', 'model.layers.6.self_attn.q_proj.base_layer.weight', 'model.layers.13.self_attn.q_proj.lora_A.default.weight', 'model.layers.8.self_attn.v_proj.base_layer.weight', 'model.layers.17.self_attn.v_proj.base_layer.weight', 'model.layers.21.self_attn.q_proj.lora_A.default.weight', 'model.layers.29.self_attn.v_proj.lora_B.default.weight', 'model.layers.18.self_attn.v_proj.lora_A.default.weight', 'model.layers.22.self_attn.v_proj.base_layer.weight', 'model.layers.19.self_attn.q_proj.base_layer.weight', 'model.layers.31.self_attn.q_proj.base_layer.weight', 'model.layers.21.self_attn.q_proj.lora_B.default.weight', 'model.layers.20.self_attn.q_proj.lora_A.default.weight', 'model.layers.27.self_attn.q_proj.base_layer.weight', 'model.layers.26.self_attn.v_proj.lora_B.default.weight', 'model.layers.6.self_attn.v_proj.base_layer.weight', 'model.layers.5.self_attn.q_proj.lora_B.default.weight', 'model.layers.1.self_attn.q_proj.base_layer.weight', 'model.layers.23.self_attn.v_proj.lora_A.default.weight', 'model.layers.20.self_attn.v_proj.lora_B.default.weight', 'model.layers.12.self_attn.v_proj.base_layer.weight', 'model.layers.5.self_attn.q_proj.lora_A.default.weight', 'model.layers.24.self_attn.v_proj.base_layer.weight', 'model.layers.8.self_attn.q_proj.base_layer.weight', 'model.layers.19.self_attn.v_proj.lora_B.default.weight', 'model.layers.9.self_attn.q_proj.lora_B.default.weight', 'model.layers.11.self_attn.q_proj.lora_B.default.weight', 'model.layers.27.self_attn.v_proj.lora_B.default.weight', 'model.layers.4.self_attn.v_proj.base_layer.weight', 'model.layers.2.self_attn.v_proj.base_layer.weight', 'model.layers.30.self_attn.v_proj.base_layer.weight', 'model.layers.16.self_attn.v_proj.lora_A.default.weight', 'model.layers.0.self_attn.q_proj.lora_B.default.weight', 'model.layers.6.self_attn.v_proj.lora_B.default.weight', 'model.layers.22.self_attn.v_proj.lora_B.default.weight', 'model.layers.20.self_attn.v_proj.base_layer.weight', 'model.layers.8.self_attn.v_proj.lora_A.default.weight', 'model.layers.10.self_attn.q_proj.base_layer.weight', 'model.layers.4.self_attn.q_proj.base_layer.weight', 'model.layers.10.self_attn.v_proj.lora_B.default.weight', 'model.layers.30.self_attn.q_proj.base_layer.weight', 'model.layers.4.self_attn.v_proj.lora_B.default.weight', 'model.layers.15.self_attn.v_proj.lora_B.default.weight', 'model.layers.23.self_attn.q_proj.lora_A.default.weight', 'model.layers.25.self_attn.q_proj.lora_B.default.weight', 'model.layers.15.self_attn.q_proj.base_layer.weight', 'model.layers.11.self_attn.v_proj.lora_B.default.weight', 'model.layers.22.self_attn.q_proj.lora_A.default.weight', 'model.layers.0.self_attn.q_proj.base_layer.weight', 'model.layers.3.self_attn.v_proj.lora_B.default.weight', 'model.layers.27.self_attn.q_proj.lora_B.default.weight', 'model.layers.27.self_attn.v_proj.base_layer.weight', 'model.layers.6.self_attn.v_proj.lora_A.default.weight', 'model.layers.24.self_attn.v_proj.lora_B.default.weight', 'model.layers.31.self_attn.v_proj.base_layer.weight', 'model.layers.15.self_attn.q_proj.lora_A.default.weight', 'model.layers.15.self_attn.v_proj.lora_A.default.weight', 'model.layers.14.self_attn.q_proj.lora_B.default.weight', 'model.layers.12.self_attn.q_proj.lora_B.default.weight', 'model.layers.1.self_attn.v_proj.lora_A.default.weight', 'model.layers.2.self_attn.q_proj.lora_A.default.weight', 'model.layers.19.self_attn.q_proj.lora_A.default.weight', 'model.layers.7.self_attn.v_proj.base_layer.weight', 'model.layers.21.self_attn.q_proj.base_layer.weight', 'model.layers.20.self_attn.q_proj.base_layer.weight', 'model.layers.11.self_attn.v_proj.base_layer.weight', 'model.layers.14.self_attn.q_proj.base_layer.weight', 'model.layers.29.self_attn.q_proj.base_layer.weight', 'model.layers.27.self_attn.q_proj.lora_A.default.weight', 'model.layers.5.self_attn.v_proj.base_layer.weight', 'model.layers.9.self_attn.q_proj.lora_A.default.weight', 'model.layers.10.self_attn.v_proj.base_layer.weight', 'model.layers.7.self_attn.v_proj.lora_B.default.weight', 'model.layers.6.self_attn.q_proj.lora_A.default.weight', 'model.layers.23.self_attn.v_proj.base_layer.weight', 'model.layers.25.self_attn.v_proj.lora_B.default.weight', 'model.layers.24.self_attn.q_proj.lora_B.default.weight', 'model.layers.5.self_attn.q_proj.base_layer.weight', 'model.layers.25.self_attn.q_proj.base_layer.weight', 'model.layers.8.self_attn.q_proj.lora_A.default.weight', 'model.layers.10.self_attn.v_proj.lora_A.default.weight', 'model.layers.29.self_attn.q_proj.lora_A.default.weight', 'model.layers.13.self_attn.q_proj.lora_B.default.weight', 'model.layers.0.self_attn.q_proj.lora_A.default.weight', 'model.layers.6.self_attn.q_proj.lora_B.default.weight', 'model.layers.30.self_attn.q_proj.lora_B.default.weight', 'model.layers.2.self_attn.v_proj.lora_B.default.weight', 'model.layers.1.self_attn.v_proj.base_layer.weight', 'model.layers.26.self_attn.v_proj.lora_A.default.weight', 'model.layers.25.self_attn.v_proj.lora_A.default.weight', 'model.layers.3.self_attn.v_proj.base_layer.weight', 'model.layers.8.self_attn.v_proj.lora_B.default.weight', 'model.layers.16.self_attn.v_proj.lora_B.default.weight', 'model.layers.26.self_attn.q_proj.lora_A.default.weight', 'model.layers.1.self_attn.v_proj.lora_B.default.weight', 'model.layers.9.self_attn.v_proj.base_layer.weight', 'model.layers.24.self_attn.q_proj.lora_A.default.weight', 'model.layers.15.self_attn.q_proj.lora_B.default.weight', 'model.layers.25.self_attn.q_proj.lora_A.default.weight', 'model.layers.30.self_attn.q_proj.lora_A.default.weight', 'model.layers.2.self_attn.q_proj.base_layer.weight', 'model.layers.18.self_attn.v_proj.base_layer.weight', 'model.layers.14.self_attn.v_proj.lora_B.default.weight', 'model.layers.21.self_attn.v_proj.lora_A.default.weight', 'model.layers.9.self_attn.v_proj.lora_A.default.weight', 'model.layers.13.self_attn.v_proj.lora_B.default.weight', 'model.layers.0.self_attn.v_proj.base_layer.weight', 'model.layers.19.self_attn.v_proj.base_layer.weight', 'model.layers.31.self_attn.q_proj.lora_A.default.weight', 'model.layers.17.self_attn.q_proj.lora_A.default.weight', 'model.layers.18.self_attn.q_proj.base_layer.weight', 'model.layers.2.self_attn.q_proj.lora_B.default.weight', 'model.layers.25.self_attn.v_proj.base_layer.weight', 'model.layers.1.self_attn.q_proj.lora_B.default.weight', 'model.layers.26.self_attn.v_proj.base_layer.weight', 'model.layers.11.self_attn.q_proj.lora_A.default.weight', 'model.layers.18.self_attn.q_proj.lora_B.default.weight', 'model.layers.31.self_attn.v_proj.lora_B.default.weight', 'model.layers.7.self_attn.q_proj.lora_B.default.weight']\n",
            "- This IS expected if you are initializing LlamaForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing LlamaForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "Some weights of LlamaForSequenceClassification were not initialized from the model checkpoint at /Content/llama_7b and are newly initialized: ['model.layers.31.self_attn.v_proj.weight', 'model.layers.10.self_attn.q_proj.weight', 'model.layers.30.self_attn.v_proj.weight', 'model.layers.6.self_attn.q_proj.weight', 'model.layers.0.self_attn.q_proj.weight', 'model.layers.2.self_attn.q_proj.weight', 'model.layers.12.self_attn.q_proj.weight', 'model.layers.2.self_attn.v_proj.weight', 'model.layers.13.self_attn.v_proj.weight', 'model.layers.13.self_attn.q_proj.weight', 'model.layers.21.self_attn.q_proj.weight', 'model.layers.8.self_attn.q_proj.weight', 'model.layers.24.self_attn.q_proj.weight', 'model.layers.19.self_attn.q_proj.weight', 'model.layers.6.self_attn.v_proj.weight', 'model.layers.1.self_attn.q_proj.weight', 'model.layers.28.self_attn.q_proj.weight', 'model.layers.17.self_attn.v_proj.weight', 'model.layers.26.self_attn.v_proj.weight', 'model.layers.9.self_attn.v_proj.weight', 'model.layers.1.self_attn.v_proj.weight', 'model.layers.12.self_attn.v_proj.weight', 'model.layers.15.self_attn.v_proj.weight', 'model.layers.23.self_attn.q_proj.weight', 'model.layers.16.self_attn.q_proj.weight', 'model.layers.7.self_attn.q_proj.weight', 'model.layers.4.self_attn.q_proj.weight', 'model.layers.14.self_attn.q_proj.weight', 'model.layers.0.self_attn.v_proj.weight', 'model.layers.28.self_attn.v_proj.weight', 'model.layers.11.self_attn.q_proj.weight', 'model.layers.9.self_attn.q_proj.weight', 'model.layers.3.self_attn.q_proj.weight', 'model.layers.31.self_attn.q_proj.weight', 'model.layers.22.self_attn.q_proj.weight', 'model.layers.7.self_attn.v_proj.weight', 'model.layers.16.self_attn.v_proj.weight', 'model.layers.11.self_attn.v_proj.weight', 'model.layers.5.self_attn.q_proj.weight', 'model.layers.25.self_attn.v_proj.weight', 'model.layers.20.self_attn.v_proj.weight', 'model.layers.30.self_attn.q_proj.weight', 'model.layers.20.self_attn.q_proj.weight', 'model.layers.22.self_attn.v_proj.weight', 'model.layers.21.self_attn.v_proj.weight', 'model.layers.17.self_attn.q_proj.weight', 'model.layers.27.self_attn.q_proj.weight', 'model.layers.5.self_attn.v_proj.weight', 'model.layers.26.self_attn.q_proj.weight', 'model.layers.4.self_attn.v_proj.weight', 'model.layers.29.self_attn.q_proj.weight', 'model.layers.18.self_attn.v_proj.weight', 'model.layers.29.self_attn.v_proj.weight', 'model.layers.8.self_attn.v_proj.weight', 'model.layers.14.self_attn.v_proj.weight', 'model.layers.24.self_attn.v_proj.weight', 'model.layers.27.self_attn.v_proj.weight', 'model.layers.15.self_attn.q_proj.weight', 'model.layers.18.self_attn.q_proj.weight', 'model.layers.25.self_attn.q_proj.weight', 'model.layers.3.self_attn.v_proj.weight', 'model.layers.23.self_attn.v_proj.weight', 'model.layers.10.self_attn.v_proj.weight', 'model.layers.19.self_attn.v_proj.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "----------------\n",
        "### Example Prompting"
      ],
      "metadata": {
        "id": "33NFsQdRnfIr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "text = \"This was a masterpiece. Not completely faithful to the books, but enthralling from beginning to end. Might be my favorite of the three.\""
      ],
      "metadata": {
        "id": "aB300mt1jrxH"
      },
      "execution_count": 58,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "inputs = tokenizer(text, return_tensors=\"pt\")"
      ],
      "metadata": {
        "id": "vevHqG1AVD3b"
      },
      "execution_count": 62,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "with torch.no_grad():\n",
        "  output = trained_model(**inputs).logits\n"
      ],
      "metadata": {
        "id": "8Y8vbuJFZFpD"
      },
      "execution_count": 63,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "predicted_class_id = output.argmax().item()\n",
        "trained_model.config.id2label[predicted_class_id]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "N-7SYr6faKIy",
        "outputId": "455cb59d-d22b-4f68-e52e-30c6e1a7a5a5"
      },
      "execution_count": 65,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'POSITIVE'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 65
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "-----------\n",
        "### Implement User Interface via Gradio Libary"
      ],
      "metadata": {
        "id": "2azo4hFpaYDs"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def user_interface(message, history):\n",
        "  inputs = tokenizer(message, return_tensors=\"pt\")\n",
        "  with torch.no_grad():\n",
        "    output = trained_model(**inputs).logits\n",
        "\n",
        "  predicted_class_id = output.argmax().item()\n",
        "  sentiment = trained_model.config.id2label[predicted_class_id]\n",
        "  return f'LLaMA-7B-Model says: {sentiment}'\n",
        "\n",
        "\n",
        "\n",
        "gr.ChatInterface(fn=user_interface).launch()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 625
        },
        "id": "UjIw_469aX2s",
        "outputId": "ee836449-fa90-42a8-91fc-27c93d93f258"
      },
      "execution_count": 73,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Setting queue=True in a Colab notebook requires sharing enabled. Setting `share=True` (you can turn this off by setting `share=False` in `launch()` explicitly).\n",
            "\n",
            "Colab notebook detected. To show errors in colab notebook, set debug=True in launch()\n",
            "Running on public URL: https://c69d28fefcdb12170d.gradio.live\n",
            "\n",
            "This share link expires in 72 hours. For free permanent hosting and GPU upgrades, run `gradio deploy` from Terminal to deploy to Spaces (https://huggingface.co/spaces)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<div><iframe src=\"https://c69d28fefcdb12170d.gradio.live\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": []
          },
          "metadata": {},
          "execution_count": 73
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "dVKHbKcw16Pm"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}